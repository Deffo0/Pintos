            +-------------------+
            |       OS 211      |
            |  TASK 1: THREADS  |
            |  DESIGN DOCUMENT  |
            +-------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Ahmed Adel Abudef
Muhammad Elkotb
Omar Metmwah
Louai Magdy Abdelhalim

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Added to timer.c:
	sleeping_list           /* List of processes currently sleeping. Processes in this list 
   								  have state set to THREAD_SLEEP. Each timer interrupt, this
								  is decremented until it reaches 0, upon which they are taken 
								  out of the sleeping list. It is intialized while intializing timer 
								  (inside timer_init)*/
							
Added to enum thread_status:
	THREAD_SLEEP            /* Indicates the thread is sleeping. */

Added to struct thread:
	wakeup_ticks           /* If sleeping, the tick we want to wake up on (used in timer sleep)*/

Added to thread.c:
	min_wakeup_ticks		 /*Takes two threads inside a list and compare between their wakeup ticks to wakeup
							   the one with smaller value. It is a helper function whic is used in 
							   timer_sleep while using list_insert_ordered to insert the sleeping thread inside
							   sleeping list*/

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

After calling out timer_sleep(), we check if the ticks provided is negative then the current thread can not 
set to sleep. Otherwise, we get the wakeup ticks of the current sleep by adding provided ticks to the timer's
current ticks and add current thread to a list of sleeping threads which we maintain then we blocked it.

>> A3: What steps are taken to minimize the amount of time spent in the timer interrupt handler?

The list of sleeping threads we maintain is ordered by the wakeup_ticks which we added to struct thread.
This is an absolute tick value that the thread should sleep until, which is set when timer_sleep() is invoked.
When we iterate over the sleeping threads we can stop iteration once we hit a thread whose wakeup_ticks value 
is later than the current tick we're on, because of this ordering. So, we simply check if the first ones in 
sleeping list is is allowed to wakeup as the are sorted and we don't need to iterate over the whole list.
Furthermore, because the tick which we want the thread to wake up on is stored
as an absolute value of time in ticks unit in the future, we don't need to update any sleep state 
in the timer interrupt handler for the sleeping threads.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

We disable interrupts in timer_sleep() before calling thread_block() (which is 
the critical section where we modify the sleeping list and then schedule 
another thread). Since interrupts are disabled for this small section, we won't 
be pre-empted by another thread, so sleeping a thread and then scheduling 
another is an atomic operation.

We switch to another thread when the current thread sleeps by calling
schedule(), so although we could use a synchronisation primitive like a
semaphore to enforce invocation of thread_block() as a critical section,
schedule() asserts that interrupts are disabled, so it makes the most sense to
disable interrupts for this critical section as they need to be off for
schedule() anyway.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

As we disable interrupts before calling thread_block() from timer_sleep(), this
ensures that timer interrupts aren't handled during the invocation of this
function which prevents race conditions occuring between multiple threads where
we may wake up sleeping threads and modify the sleep list.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to another design you considered?

We chose this design because it does a fairly low amount of processing in the
timer interrupt handler. As this is called every tick, this is important. Our
initial design used an ordered list of sleeping threads, and each thread
stored the number of ticks to sleep for. In the timer interrupt handler we
would increment the number of ticks of the timer tick, and then wake up the 
thread when its wakeup_ticks time has come.

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Added to `struct thread':

    int effectivePriority:
        the original priority of a thread that can only change when calling thread_set_priority,
        used to save the original priority when donation occurs and used when donation finishes to ensure
        that a thread has its original priority.
    int priority:
        the current real priority of a thread that changes when donation occur, always equals
        to effectivePriority when there are no donation at the moment.
    bool donee:
        A boolean value that is true if the thread does not have its original priority (priority > effectivePriority)
        when another thread donates its priority to the thread, False if the thread has its original priority (if priority = effectivePriority)
    struct lock* wait_lock:
        A pointer to the lock that the thread waiting on whilst donating its priority to another lower priority thread,
        NULL when no donating occurs.
    int nested_depth:
        An int value that controls the maximum depth of nested donation, default is 10.
    struct donate_list:
        list of threads donating their priorities to the thread 
    struct list_elem donateelem:
        this type of list element is responsible for pointing to the elements in the donate_list.
  - struct list_element readyeleme:
	  this type of list element is responsible for pointing to the elements in the readylist.

Added to `thread.c':
  - list readylist:
	    this list contains the ready threads in the memory in a sorted way.
  


>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

Say we have lock L,  thread A having original priority P1 and currently acquiring Lock L, and thread B of priority P2 where P2 > P1

then thread B wants to acquire Lock L --> ~ Thread B wait_lock points to lock L 
                                          ~ Thread B is added to Thread A donate_list(ordered insertion)
                                          ~ Loop through the chain of donations by dereferencing wait_lock pointers and changing all lock holders priority to P2 (in case of nested donation) until it hits NULL.
                                          ~ sets Thread A donee to true.

when thread A wants to release Lock L --> ~ Thread B (the highest waiting priority threaed, in example here is thread B) is removed from Thread A donate_list.
                                          ~ if Thread A donate_list is empty then donation stops and Thread A is back to its original priority (effectivePriority).
                                          ~ if thread A donate_list is not empty then its priority is set to the highest waiting thread from Thead A donate_list
                                          
By using a list for donating threads for each thread and a pointer to a lock. it is ensured that every thread holds its donators,
which makes it easier to track mulitple donators and nested donation by only dereferencing wait_lock to their holders.


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

Any thread insertion to the readylist or to the waiting list in sema_down, lock_acquire, cond_wait, thread_yield and thread_unblock
was done using list_insert_ordered according to the priority of the thread,
so that the highest priority thread is always resident in the front of the waiting/ready list. 




>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

Say we have lock L,  thread A having original priority P1 and currently acquiring Lock L, and thread B of priority P2 where P2 > P1


--> Thread A donee is set to true indicating that Thread A is being donated to.
--> Thread B wait_lock pointer is set to Lock L.
--> Thread B in inserted to Thread A donate_list (ordered insertion)
--> A temp lock pointer is initialized to Lock L
--> iterating through all chained threads by dereferencing wait_lock until it becomes NULL (where we encounter the head of the chain)
--> while iterating , we change every priority of the threads we encounter to P2 (if P2 is greater than each ecountered thread priority).
--> we sort the donate_list of the temp_lock holder thread so that if donate_list descending ordered is presreved.
--> temp_lock is set to the wait_lock of temp_lock holder thread
--> maximum nested depth is 10

nested depth is handled by dereferencing wait_lock on each thread on the chain of threads,
we do that dereferencing by starting with the current holder then dereference its wait_lock to get its holder and get the wait_lock and so one ....




>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

Say we have lock L,  thread A having original priority P1 and currently acquiring Lock L, and thread B of priority P2 where P2 > P1

--> we remove Thread B from thread A donate list.
--> if thread A donate_list empty then thread A should have its original priority and Thread A donee is set to false.
--> if thread A donate_list not empty then thread A should change its priority to the highest waiting thread priority fron thread A donate_list.


---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

By disabling interupts before changing the priority of the current thread because it represents the critical section/shared resource in this function and enabling it after performing yield if there is a higher priority thread in the ready list.

---- RATIONALE ----


>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?


This design was chosen because it minimizes the cycles between the scheduler and the threads because it performs yield only if the new/unblocked/ modified thread has higher priority than the current thread

 


              Advanced Scheduling
							===================
---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Struct recent_Cpu_real
	it includes an integer field dealt with as fixed point value
	it is a field in thread struct
	it represents the time taken by each thread on the cpu either running or waiting
	declaration: struct recent_cpu_real recentCpu;
	
Struct nice_value_real
	it includes an integer
	it is a field in thread struct
	it represents how easy the current thread can yield the cpu
	declaration: struct nice_value_real niceValue;
	
Struct load_avg_real
	it includes an integer field dealt with as fixed point value
	it is a global variable in thread.c
	it represents an estimate of the no. of ready threads in the last minute
	declaration: struct load_avg_real loadAvg;
	

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer   recent_cpu   priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  63  61  59      A
 4      4   0   0  62  61  59      A
 8      8   0   0  61  61  59      B  
 12     8   4   0  61  60  59      A
 16     12  4   0  60  60  59      B
 20     12  8   0  60  59  59      A
 24     16  8   0  59  59  59      C
 28     16  8   4  59  59  58      B
 32     16  12  4  59  58  58      A
 36     20  12  4  58  58  58      C 

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behaviour of your scheduler?

- yes, there was an ambiguity concerning which thread to run when two or more have equal priorities
- our idea to solve it is to choose another last thread of this priority and insert the previous thread in its correct place
in the descendingly ordered ready_list
- yes, it matches the scheduler behaviour due to ordering also the chosen thread to run still have the max priority

> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

we put all the scheduling logic in the function thread_tick() called inside timer_interrupt()
- where each tick, the recent cpu of the current thread is modified
each fourth tick, the priority of threads is updated, ready list is sorted and current thread may yield
each second (100 ticks), the recent cpu and load average of all threads are modified
- actually it takes a long time at the fourth tick and every one second which may affect the performance of thread_tick() and
slow it down

  
 
 ---- RATIONALE ----
 
 > C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the task, how might you choose to
>> refine or improve your design?

advantages are	- choosing the next thread to run is fast as the ready list is always sorted descindingly
	        - calculations are quite fast
disadvantages are - it takes a long time to sort the ready list after updating priorities
		   - updating the priorities itself requires looping through all threads
actually if we had extra time, we would have thought of another soln such as deriving an estimates for the priorities after
a certain period of time or updating the priorities, recent_cpu and load Averages in batches

>> C6: The assignment explains arithmetic for fixed-point mathematics in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point mathematics, that is, an abstract
>> data type and/or a set of functions or macros to manipulate
>> fixed-point numbers, why did you do so?  If not, why not?

- actually, the chosen implementation is quite easy and fast depending on binary shift operator >> and <<
- I did it for several reasons such as - reusability   - encapsulation